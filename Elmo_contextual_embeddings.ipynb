{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Elmo contextual embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljyslyc/comment-analysis/blob/master/Elmo_contextual_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU3MR71VpovV",
        "colab_type": "text"
      },
      "source": [
        "# ELMo\n",
        "\n",
        "Note that you will need to use the non-GPU accelerated run-time on this notebook due to the large memory useage of the ELMo model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q8JYD36CdYr",
        "colab_type": "text"
      },
      "source": [
        "## Imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qgy7Jmr5wSx",
        "colab_type": "code",
        "outputId": "5de82388-46e7-441e-dfb7-f217a5112b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn import preprocessing\n",
        "from IPython.display import HTML\n",
        "import logging\n",
        "!python -m spacy download en_core_web_md #you will need to install this on first load\n",
        "!python -m spacy download en #you will need to install this on first load\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy import displacy\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "logging.getLogger('tensorflow').disabled = True #OPTIONAL - to disable outputs from Tensorflow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz#egg=en_core_web_md==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-be66038ab9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_md'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m#OPTIONAL - to disable outputs from Tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMknjdZpCgR0",
        "colab_type": "text"
      },
      "source": [
        "## Get the data \n",
        "\n",
        "The below downloads a Pandas Dataframe which is publically hosted on Google Drive (this should therefore work for anyone)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Oy1nXa6dLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "\n",
        "file_id = '1M_XljfV5t_nGjvhyfTPO9n2nfOweMwYx'\n",
        "destination = 'temp'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "combined = pd.read_pickle('temp')\n",
        "\n",
        "combined.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxkL4RXwVToa",
        "colab_type": "text"
      },
      "source": [
        "## Create sentence embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIhHrFsmOC6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://tfhub.dev/google/elmo/2\"\n",
        "embed = hub.Module(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df76NYQcnQ3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined.loc[combined.Company.str.contains(\"Asos\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU_MS6MXVe_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = combined.iloc[494].text\n",
        "import re\n",
        "\n",
        "text = text.lower().replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0',' ')\n",
        "text = ' '.join(text.split())\n",
        "doc = nlp(text)\n",
        "\n",
        "sentences = []\n",
        "for i in doc.sents:\n",
        "  if len(i)>1:\n",
        "    sentences.append(i.string.strip())\n",
        "    \n",
        "len(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjGbrUhapvXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsGkzCltOMOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = embed(\n",
        "    sentences,\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA6BO4a_Oswf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.tables_initializer())\n",
        "  x = sess.run(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwlt2Husrtzo",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the sentences using PCA and TSNE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAGj0yJyUD3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "y = pca.fit_transform(x)\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "y = TSNE(n_components=2).fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGUyrjcMfdJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "\n",
        "data = [\n",
        "    go.Scatter(\n",
        "        x=[i[0] for i in y],\n",
        "        y=[i[1] for i in y],\n",
        "        mode='markers',\n",
        "        text=[i for i in sentences],\n",
        "    marker=dict(\n",
        "        size=16,\n",
        "        color = [len(i) for i in sentences], #set color equal to a variable\n",
        "        opacity= 0.8,\n",
        "        colorscale='Viridis',\n",
        "        showscale=False\n",
        "    )\n",
        "    )\n",
        "]\n",
        "layout = go.Layout()\n",
        "layout = dict(\n",
        "              yaxis = dict(zeroline = False),\n",
        "              xaxis = dict(zeroline = False)\n",
        "             )\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "file = plot(fig, filename='Sentence encode.html')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('Sentence encode.html') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAu1zHOjrzzj",
        "colab_type": "text"
      },
      "source": [
        "## Create a semantic search engine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfgIfOxXQ8ba",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Sementic search\n",
        "#@markdown Enter a set of words to find matching sentences. 'results_returned' can beused to modify the number of matching sentences retured. To view the code behind this cell, use the menu in the top right to unhide...\n",
        "search_string = \"code of ethics\" #@param {type:\"string\"}\n",
        "results_returned = \"3\" #@param [1, 2, 3]\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "embeddings2 = embed(\n",
        "    [search_string],\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"default\"]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.tables_initializer())\n",
        "  search_vect = sess.run(embeddings2)\n",
        "  \n",
        "\n",
        "cosine_similarities = pd.Series(cosine_similarity(search_vect, x).flatten())\n",
        "output =\"\"\n",
        "for i,j in cosine_similarities.nlargest(int(results_returned)).iteritems():\n",
        "  output +='<p style=\"font-family:verdana; font-size:110%;\"> '\n",
        "  for i in sentences[i].split():\n",
        "    if i.lower() in search_string:\n",
        "      output += \" <b>\"+str(i)+\"</b>\"\n",
        "    else:\n",
        "      output += \" \"+str(i)\n",
        "  output += \"</p><hr>\"\n",
        "    \n",
        "output = '<h3>Results:</h3>'+output\n",
        "display(HTML(output))\n",
        "#   print(sentences[i])\n",
        "#   print('\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}