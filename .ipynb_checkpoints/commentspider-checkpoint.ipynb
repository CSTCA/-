{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "##调用getMerchantComment接口获取评论json\n",
    "def getShopPage(shopID,offSet):\n",
    "    simulateChromeBrowserData = {\n",
    "        'Accept':'*/*',\n",
    "        'Accept-Encoding':'gzip, deflate',\n",
    "        'Accept-Language':'zh-CN,zh;q=0.8',\n",
    "        'Connection':'keep-alive',\n",
    "        'Host':'sz.meituan.com',\n",
    "        'Referer':'http://wh.meituan.com/meishi/',\n",
    "        # 'Cookie': '_lxsdk_cuid=16212a00d8ec8-07cdb6596bad8e-178123e-1fa400-16212a00d8fc8; lat=22.780886; lng=113.906362; client-id=34908f62-ea11-4211-b60a-f62c32288b2e; uuid=9be4f96971ac4c9cab4c.1520730903.1.0.0; webloc_geo=22.527181%2C113.938582%2Cwgs84; ci=30; _lxsdk=16212a1cddfc8-011369480302e7-178123e-1fa400-16212a1cddfc8; __mta=247430459.1520730902128.1520731016684.1520731025187.5; _lxsdk_s=16212a00d8f-c83-6e-376%7C%7C9',\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'\n",
    "    }\n",
    "    purl='https://www.meituan.com/meishi/api/poi/getMerchantComment'\n",
    "    params = {\n",
    "        'id' : shopID,\n",
    "        'userId' : 0,\n",
    "        'offset' : offSet*10,#偏移量，也是页码信息\n",
    "        'pageSize' : 10,\n",
    "        'sortType' : 1\n",
    "    }\n",
    "    page = requests.get(purl,params=params,headers=simulateChromeBrowserData)\n",
    "    return page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataClean(comment):  #只保留中文\n",
    "    pattern = re.compile(r'[^\\u4e00-\\u9fa5]')\n",
    "    commentc = re.sub(pattern, '', comment)\n",
    "    return commentc\n",
    "\n",
    "def parse_POI_Shop_Json(shop_json):\n",
    "    one_comment_data = pd.DataFrame()\n",
    "    if 'data'in shop_json:\n",
    "        for eachShopInfo in shop_json.get('data').get('comments'):\n",
    "            Comment = dataClean(eachShopInfo.get('comment'))\n",
    "            if not Comment:\n",
    "                continue\n",
    "            IsGreet = 1 if eachShopInfo.get('star')>= 30 else 0\n",
    "            one_comment_data = one_comment_data.append(pd.DataFrame({'Comment':[Comment],'IsGreet':[IsGreet]}))\n",
    "    return one_comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Comment_datas = pd.DataFrame();\n",
    "# allCommentNum商家的最大评论数\n",
    "allCommentNum=26303\n",
    "for i in range(allCommentNum//10):\n",
    "    page = getShopPage(74779,i)\n",
    "    #print(page.url)\n",
    "    # print(page.json())\n",
    "    Comment_data = parse_POI_Shop_Json(page.json())\n",
    "    Comment_datas = Comment_datas.append(Comment_data)\n",
    "print(Comment_datas)\n",
    "Comment_datas.to_csv('Comment_datas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_data=np.array(Comment_datas.get('Comment'))\n",
    "Y_data=np.array(Comment_datas.get('IsGreet'))\n",
    "X_test_data=X_data[1400:1485]\n",
    "Y_test_data=Y_data[1400:1485]\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "nums = np.arange(1400)\n",
    "# 随机打乱12000个训练数据\n",
    "np.random.shuffle(nums)\n",
    "for i in nums:\n",
    "    X_train.append(X_data[1])\n",
    "    y_train.append(Y_data[1])\n",
    "\n",
    "# 随机打乱1600个测试数据\n",
    "nums_ = np.arange(85)\n",
    "np.random.shuffle(nums_)  # shuffle改变的是自身的内容\n",
    "for i in nums_:\n",
    "    X_test.append(X_test_data [1])\n",
    "    y_test.append(Y_test_data [1])\n",
    "\n",
    "# list转Numpy数组\n",
    "X_train= np.array(X_train)\n",
    "X_test= np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkuseg\n",
    "seg = pkuseg.pkuseg()           # 以默认配置加载模型\n",
    "for items in X_data:\n",
    "    text = seg.cut(items)  # 进行分词  \n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient\n",
    "# 将待训练的中文数据转换为（，768）维的句向量\n",
    "input_train = bc.encode(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "model = Sequential()\n",
    "# 搭建模型\n",
    "model.add(Dense(32, activation='relu', input_shape=(768,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.train.AdamOptimizer(),\n",
    "    metrics=['acc']\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "epochs = range(1, len(history_dict['acc']) + 1)\n",
    "# 绘图部分\n",
    "plt.figure()\n",
    "plt.plot(epochs, history_dict['acc'], 'b', label='acc')\n",
    "plt.plot(epochs, history_dict['val_acc'], 'bo', label='val_acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    batch_size=63,\n",
    "    verbose=1\n",
    ")\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
